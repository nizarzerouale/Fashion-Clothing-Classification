{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Application 1 - Step 1 - Import the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import keras\n",
    "import np_utils\n",
    "from keras.optimizers.legacy import SGD\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras import layers\n",
    "from matplotlib import pyplot\n",
    "import cv2\n",
    "from keras.src.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 9 images\n",
    "def displayFirst9ImagesWithCV(trainX):\n",
    "    for i in range(9):  \n",
    "        img = trainX[i]\n",
    "        window_name = 'Image ' + str(i+1)\n",
    "        cv2.imshow(window_name, img)\n",
    "        \n",
    "        # Wait for a key press to move to the next image\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "    # Close all the windows\n",
    "    cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarizeLearningCurvesPerformances(histories, accuracyScores):\n",
    "    for i in range(len(histories)):\n",
    "        # plot loss\n",
    "        pyplot.subplot(211)\n",
    "        pyplot.title('Cross Entropy Loss')\n",
    "        pyplot.plot(histories[i].history['loss'], color='green', label='train')\n",
    "        pyplot.plot(histories[i].history['val_loss'], color='red', label='test')\n",
    "\n",
    "        # plot accuracy\n",
    "        pyplot.subplot(212)\n",
    "        pyplot.title('Classification Accuracy')\n",
    "        pyplot.plot(histories[i].history['accuracy'], color='green', label='train')\n",
    "        pyplot.plot(histories[i].history['val_accuracy'], color='red', label='test')\n",
    "\n",
    "        #print accuracy for each split\n",
    "        print(\"Accuracy for set {} = {}\".format(i, accuracyScores[i]))\n",
    "    pyplot.show()\n",
    "    print('Accuracy: mean = {:.3f} std = {:.3f}, n = {}'.format(np.mean(accuracyScores) * 100, np.std(accuracyScores) * 100, len(accuracyScores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(trainX, trainY, testX, testY):\n",
    "\n",
    "    #TODO - Application 1 - Step 4a - reshape the data to be of size [samples][width][height][channels]\n",
    "    trainX = trainX.reshape((trainX.shape[0],28,28,1))\n",
    "    testX = testX.reshape((testX.shape[0],28,28,1))\n",
    "    \n",
    "    #TODO - Application 1 - Step 4b - normalize the input values\n",
    "    trainX = trainX / 255\n",
    "    testX = testX / 255\n",
    "    \n",
    "    #TODO - Application 1 - Step 4c - Transform the classes labels into a binary matrix\n",
    "    trainY = to_categorical(trainY, 10)\n",
    "    testY = to_categorical(testY, 10)\n",
    "    \n",
    "    return trainX, trainY, testX, testY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defineModel(input_shape, num_classes):\n",
    "\n",
    "    #TODO - Application 1 - Step 6a - Initialize the sequential model\n",
    "    model = keras.models.Sequential()\n",
    "\n",
    "    #TODO - Application 1 - Step 6b - Create the first hidden layer as a convolutional layer\n",
    "    model.add(layers.Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=input_shape, kernel_initializer='he_uniform', padding='same'))\n",
    "    \n",
    "    #TODO - Application 1 - Step 6c - Define the pooling layer\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Add Dropout\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    \n",
    "    #TODO - Application 1 - Step 6d - Define the flatten layer\n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    #TODO - Application 1 - Step 6e - Define a dense layer of size 16\n",
    "    model.add(layers.Dense(512, activation='relu', kernel_initializer='he_uniform'))\n",
    "    \n",
    "    #TODO - Application 1 - Step 6f - Define the output layer\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    #TODO - Application 1 - Step 6g - Compile the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=SGD(learning_rate = 0.001, momentum = 0.9), metrics=['accuracy'])\n",
    "\n",
    "    #Save the model\n",
    "    #model.save('Fashion_MNIST_model.h5')\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defineTrainAndEvaluateClassic(trainX, trainY, testX, testY):\n",
    "\n",
    "    #TODO - Application 1 - Step 6 - Call the defineModel function\n",
    "    input_shape = (28,28,1)\n",
    "    num_classes = 10\n",
    "    model = defineModel(input_shape, num_classes)\n",
    "    \n",
    "    #TODO - Application 1 - Step 7 - Train the model\n",
    "    model.fit(trainX, trainY, validation_data=(testX, testY), epochs=20, batch_size=32, verbose=2)\n",
    "    \n",
    "    #TODO - Application 1 - Step 8 - Evaluate the model\n",
    "    #Evaluate the model on the test data\n",
    "    scores = model.evaluate(testX, testY, verbose=0)\n",
    "\n",
    "    # Print the classification error rate\n",
    "    print(f\"Classification Error Rate: {(1-scores[1]) * 100:.2f}%\")\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defineTrainAndEvaluateKFolds(trainX, trainY, testX, testY):\n",
    "    k_folds = 5\n",
    "    accuracyScores = []\n",
    "    histories = []\n",
    "\n",
    "    #Application 2 - Step 2 - Prepare the cross validation datasets\n",
    "    kfold = KFold(k_folds, shuffle=True, random_state=1)\n",
    "    for train_idx, val_idx in kfold.split(trainX):\n",
    "\n",
    "        #TODO - Application 2 - Step 3 - Select data for train and validation\n",
    "        trainX_fold, trainY_fold = trainX[train_idx], trainY[train_idx]\n",
    "        valX_fold, valY_fold = trainX[val_idx], trainY[val_idx]\n",
    "\n",
    "        #TODO - Application 2 - Step 4 - Build the model - Call the defineModel function\n",
    "        num_classes = 10\n",
    "        model = defineModel((28, 28, 1), num_classes)\n",
    "\n",
    "        #TODO - Application 2 - Step 5 - Fit the model\n",
    "        history = model.fit(trainX_fold, trainY_fold, epochs=5, batch_size=32, validation_data=(valX_fold, valY_fold), verbose=2)\n",
    "\n",
    "        #TODO - Application 2 - Step 6 - Save the training related information in the histories list\n",
    "        histories.append(history)\n",
    "\n",
    "        #TODO - Application 2 - Step 7 - Evaluate the model on the test dataset\n",
    "        _, accuracy = model.evaluate(testX, testY, verbose=0)\n",
    "\n",
    "        #TODO - Application 2 - Step 8 - Save the accuracy in the accuracyScores list\n",
    "        accuracyScores.append(accuracy)\n",
    "\n",
    "    return histories, accuracyScores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    #TODO - Application 1 - Step 2 - Load the Fashion MNIST dataset in Keras\n",
    "    (trainX, trainY), (testX, testY) = fashion_mnist.load_data()\n",
    "    \n",
    "    # Display the first 9 images\n",
    "    #displayFirst9ImagesWithCV(trainX)\n",
    "    \n",
    "    #TODO - Application 1 - Step 3 - Print the size of the train/test dataset\n",
    "    #print(trainX.shape[0])\n",
    "    \n",
    "    #TODO - Application 1 - Step 4 - Call the prepareData method\n",
    "    #trainX, trainY, testX, testY = prepareData(trainX, trainY, testX, testY)\n",
    "    \n",
    "    #TODO - Application 1 - Step 5 - Define, train and evaluate the model in the classical way\n",
    "    #defineTrainAndEvaluateClassic(trainX, trainY, testX, testY)\n",
    "    \n",
    "    #TODO - Application 2 - Step 1 - Define, train and evaluate the model using K-Folds strategy\n",
    "    histories, accuracyScores = defineTrainAndEvaluateKFolds(trainX, trainY, testX, testY)\n",
    "    \n",
    "    #TODO - Application 2 - Step9 - System performance presentation\n",
    "    summarizeLearningCurvesPerformances(histories, accuracyScores)\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 - 25s - loss: 0.5240 - accuracy: 0.8131 - val_loss: 0.4410 - val_accuracy: 0.8367 - 25s/epoch - 13ms/step\n",
      "Epoch 2/20\n",
      "1875/1875 - 24s - loss: 0.3920 - accuracy: 0.8597 - val_loss: 0.3874 - val_accuracy: 0.8585 - 24s/epoch - 13ms/step\n",
      "Epoch 3/20\n",
      "1875/1875 - 24s - loss: 0.3515 - accuracy: 0.8721 - val_loss: 0.3397 - val_accuracy: 0.8796 - 24s/epoch - 13ms/step\n",
      "Epoch 4/20\n",
      "1875/1875 - 24s - loss: 0.3211 - accuracy: 0.8832 - val_loss: 0.3432 - val_accuracy: 0.8755 - 24s/epoch - 13ms/step\n",
      "Epoch 5/20\n",
      "1875/1875 - 24s - loss: 0.3015 - accuracy: 0.8914 - val_loss: 0.3095 - val_accuracy: 0.8891 - 24s/epoch - 13ms/step\n",
      "Epoch 6/20\n",
      "1875/1875 - 24s - loss: 0.2848 - accuracy: 0.8950 - val_loss: 0.2994 - val_accuracy: 0.8884 - 24s/epoch - 13ms/step\n",
      "Epoch 7/20\n",
      "1875/1875 - 24s - loss: 0.2695 - accuracy: 0.9019 - val_loss: 0.2911 - val_accuracy: 0.8948 - 24s/epoch - 13ms/step\n",
      "Epoch 8/20\n",
      "1875/1875 - 24s - loss: 0.2551 - accuracy: 0.9072 - val_loss: 0.2884 - val_accuracy: 0.8950 - 24s/epoch - 13ms/step\n",
      "Epoch 9/20\n",
      "1875/1875 - 24s - loss: 0.2435 - accuracy: 0.9123 - val_loss: 0.2883 - val_accuracy: 0.8939 - 24s/epoch - 13ms/step\n",
      "Epoch 10/20\n",
      "1875/1875 - 25s - loss: 0.2338 - accuracy: 0.9137 - val_loss: 0.2881 - val_accuracy: 0.8954 - 25s/epoch - 13ms/step\n",
      "Epoch 11/20\n",
      "1875/1875 - 25s - loss: 0.2247 - accuracy: 0.9186 - val_loss: 0.2803 - val_accuracy: 0.8954 - 25s/epoch - 13ms/step\n",
      "Epoch 12/20\n",
      "1875/1875 - 26s - loss: 0.2164 - accuracy: 0.9205 - val_loss: 0.2630 - val_accuracy: 0.9056 - 26s/epoch - 14ms/step\n",
      "Epoch 13/20\n",
      "1875/1875 - 27s - loss: 0.2070 - accuracy: 0.9247 - val_loss: 0.2559 - val_accuracy: 0.9071 - 27s/epoch - 14ms/step\n",
      "Epoch 14/20\n",
      "1875/1875 - 28s - loss: 0.2013 - accuracy: 0.9263 - val_loss: 0.2550 - val_accuracy: 0.9090 - 28s/epoch - 15ms/step\n",
      "Epoch 15/20\n",
      "1875/1875 - 27s - loss: 0.1933 - accuracy: 0.9306 - val_loss: 0.2539 - val_accuracy: 0.9066 - 27s/epoch - 15ms/step\n",
      "Epoch 16/20\n",
      "1875/1875 - 27s - loss: 0.1869 - accuracy: 0.9321 - val_loss: 0.2504 - val_accuracy: 0.9110 - 27s/epoch - 14ms/step\n",
      "Epoch 17/20\n",
      "1875/1875 - 27s - loss: 0.1794 - accuracy: 0.9353 - val_loss: 0.2447 - val_accuracy: 0.9124 - 27s/epoch - 14ms/step\n",
      "Epoch 18/20\n",
      "1875/1875 - 29s - loss: 0.1741 - accuracy: 0.9371 - val_loss: 0.2498 - val_accuracy: 0.9092 - 29s/epoch - 15ms/step\n",
      "Epoch 19/20\n",
      "1875/1875 - 28s - loss: 0.1681 - accuracy: 0.9397 - val_loss: 0.2423 - val_accuracy: 0.9127 - 28s/epoch - 15ms/step\n",
      "Epoch 20/20\n",
      "1875/1875 - 29s - loss: 0.1623 - accuracy: 0.9417 - val_loss: 0.2429 - val_accuracy: 0.9132 - 29s/epoch - 16ms/step\n",
      "Classification Error Rate: 8.68%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
